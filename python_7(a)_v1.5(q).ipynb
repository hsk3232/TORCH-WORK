{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, csv_file=\"data/SBUX.csv\", seq_length=10, train_ratio=0.8, is_train=True):\n",
    "        self.seq_length = seq_length\n",
    "        self.is_train = is_train\n",
    "\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "        df = df.sort_values(\"Date\")\n",
    "        df = self._add_techinical_indicators(df)\n",
    "\n",
    "        features_cols = [\"Close\", \"Volume\", \"MA_5\", \"MA_20\", \n",
    "                         \"RSI\", \"Volatility\", \"Price_Change\", \"Volume_MA\"]\n",
    "        \n",
    "        data = df[features_cols].values\n",
    "\n",
    "        # 결측값 처리\n",
    "        data_df = pd.DataFrame(data)\n",
    "        data = data_df.ffill().bfill().values\n",
    "        \n",
    "        self.scaler = RobustScaler()\n",
    "        scaled_data = self.scaler.fit_transform(data)\n",
    "\n",
    "        X, y = self._create_sequences(scaled_data, seq_length)\n",
    "\n",
    "        train_size = int(len(X) * train_ratio)\n",
    "\n",
    "        if self.is_train:\n",
    "            self.X = torch.FloatTensor(X[:train_size])\n",
    "            self.y = torch.FloatTensor(y[:train_size])\n",
    "            self.dates = df['Date'].iloc[seq_length : train_size + seq_length]\n",
    "        else:\n",
    "            self.X = torch.FloatTensor(X[train_size:])\n",
    "            self.y = torch.FloatTensor(y[train_size:])\n",
    "            self.dates = df['Date'].iloc[train_size + seq_length :]\n",
    "\n",
    "    def _create_sequences(self, data, seq_length):\n",
    "        xs, ys = [], []\n",
    "        for i in range(len(data) - seq_length):\n",
    "            x = data[i:i + seq_length]\n",
    "            y = data[i + seq_length]\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "        return np.array(xs), np.array(ys)\n",
    "    \n",
    "    def _add_techinical_indicators(self, df):\n",
    "        # 이동평균\n",
    "        df[\"MA_5\"] = df[\"Close\"].rolling(window=5).mean()\n",
    "        df[\"MA_20\"] = df[\"Close\"].rolling(window=20).mean()\n",
    "\n",
    "        # RSI\n",
    "        delta = df[\"Close\"].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "        rs = gain / loss\n",
    "        df[\"RSI\"] = 100 - (100 / (1 + rs))\n",
    "\n",
    "        # 변동성\n",
    "        df[\"Volatility\"] = df[\"Close\"].rolling(window=14).std()\n",
    "\n",
    "        # 가격 변화율\n",
    "        df[\"Price_Change\"] = df[\"Close\"].pct_change()\n",
    "\n",
    "        # 거래량 이동평균\n",
    "        df[\"Volume_MA\"] = df[\"Volume\"].rolling(window=10).mean()\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 10\n",
    "batch_size = 16\n",
    "\n",
    "train_dataset = TimeSeriesDataset(seq_length=seq_length, is_train=True)\n",
    "test_dataset = TimeSeriesDataset(seq_length=seq_length, is_train=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        return self.fc(h_n.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 8\n",
    "hidden_size = 50\n",
    "output_size = 1\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "num_layers_bilstm = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\TORCH-WORK\\.venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:610: UserWarning: Using a target size (torch.Size([16, 8])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\TORCH-WORK\\.venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:610: UserWarning: Using a target size (torch.Size([2, 8])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Epoch [10/100], Loss: 0.2010\n",
      "LSTM Epoch [20/100], Loss: 0.7366\n",
      "LSTM Epoch [30/100], Loss: 2.3554\n",
      "LSTM Epoch [40/100], Loss: 0.5263\n",
      "LSTM Epoch [50/100], Loss: 0.6595\n",
      "LSTM Epoch [60/100], Loss: 3.5294\n",
      "LSTM Epoch [70/100], Loss: 0.3971\n",
      "LSTM Epoch [80/100], Loss: 0.1801\n",
      "LSTM Epoch [90/100], Loss: 0.9690\n",
      "LSTM Epoch [100/100], Loss: 0.1705\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (49,1) doesn't match the broadcast shape (49,8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m         lstm_test_predictions\u001b[38;5;241m.\u001b[39mappend(outputs\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     24\u001b[0m lstm_test_predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(lstm_test_predictions)\n\u001b[1;32m---> 25\u001b[0m lstm_test_predictions_rescaled \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_test_predictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m y_test_rescaled \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39minverse_transform(test_dataset\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[1;32mc:\\TORCH-WORK\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1735\u001b[0m, in \u001b[0;36mRobustScaler.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_scaling:\n\u001b[1;32m-> 1735\u001b[0m         X \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[0;32m   1736\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_centering:\n\u001b[0;32m   1737\u001b[0m         X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenter_\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (49,1) doesn't match the broadcast shape (49,8)"
     ]
    }
   ],
   "source": [
    "lstm_model = LSTMModel(input_size, hidden_size, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    lstm_model.train()\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = lstm_model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'LSTM Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "lstm_model.eval()\n",
    "lstm_test_predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        outputs = lstm_model(batch_X)\n",
    "        lstm_test_predictions.append(outputs.cpu().numpy())\n",
    "\n",
    "lstm_test_predictions = np.concatenate(lstm_test_predictions)\n",
    "lstm_test_predictions_rescaled = train_dataset.scaler.inverse_transform(lstm_test_predictions)\n",
    "y_test_rescaled = train_dataset.scaler.inverse_transform(test_dataset.y.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test_rescaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(test_dataset\u001b[38;5;241m.\u001b[39mdates, \u001b[43my_test_rescaled\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m실제 가격\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(test_dataset\u001b[38;5;241m.\u001b[39mdates, lstm_test_predictions_rescaled, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM 예측 가격\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m날짜\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test_rescaled' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(test_dataset.dates, y_test_rescaled, label='실제 가격', color='blue')\n",
    "plt.plot(test_dataset.dates, lstm_test_predictions_rescaled, label='LSTM 예측 가격', color='red', linestyle=':')\n",
    "plt.xlabel('날짜')\n",
    "plt.ylabel('주식 가격')\n",
    "plt.title('SBUX 주식 가격 예측 with RNN')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.gca().xaxis.set_major_locator(plt.MaxNLocator(nbins=15))\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN 모델 테스트 MSE (원래 스케일): 3.1161\n",
      "LSTM 모델 테스트 MSE (원래 스케일): 3.1965\n",
      "GRU 모델 테스트 MSE (원래 스케일): 3.8633\n",
      "BiLSTM 모델 테스트 MSE (원래 스케일): 3.2388\n"
     ]
    }
   ],
   "source": [
    "lstm_mse = np.mean((y_test_rescaled - lstm_test_predictions_rescaled)**2)\n",
    "print(f'LSTM 모델 테스트 MSE (원래 스케일): {lstm_mse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
