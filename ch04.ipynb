{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1a02d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"D2Coding\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5d2b5ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, dataframe, target_column=None, transform=None, is_train=True):\n",
    "        self.dataframe = dataframe.copy()\n",
    "        self.target_column = target_column\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        self._preprocess()\n",
    "        \n",
    "        # / train_set과 test_set의 내용이 다름으로 블리안으로 처리 해야 함\n",
    "        if self.is_train and target_column:\n",
    "            self.targets = self.dataframe[target_column].values # sklearn과 다르게 값만 넣어야 함. \n",
    "            self.features = self.dataframe.drop([target_column], axis=1).values # sklearn과 다르게 값만 넣어야 함. \n",
    "        else:\n",
    "            self.targets = None\n",
    "            self.features = self.dataframe.values\n",
    "        \n",
    "    \n",
    "    ########################### 반드시 숙지 할 것 #############################\n",
    "    # 데이터 전처리 => 안하고 결과 보고 싶으면, 결정트리 앙상블로 돌림.\n",
    "    # 외부에서 부르지 말라. 선언 _preprocess        \n",
    "    def _preprocess(self):\n",
    "        # 1. 불필요한 컬럼 삭제\n",
    "        \n",
    "        # 1-1. 삭제할 컬럼 선언\n",
    "        columns_to_drop = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"]\n",
    "        # 1-2. 컬럼 있는지 확인\n",
    "        existing_columns = [\n",
    "            col for col in columns_to_drop if col in self.dataframe.columns\n",
    "        ]\n",
    "        \n",
    "        # 1-3. 실질적으로 삭제\n",
    "        if existing_columns:\n",
    "            self.dataframe.drop(existing_columns, axis=1, inplace=True)\n",
    "\n",
    "        # 2. 나이 결측값 처리 (중앙값으로 처리)\n",
    "        if \"Age\" in self.dataframe.columns:\n",
    "            self.dataframe[\"Age\"].fillna(self.dataframe[\"Age\"].median(), inplace=True)\n",
    "\n",
    "        # 3. 승선항구 결측값 처리 (최빈값 - 최대로 많은 빈도(언급)가 나온 값)\n",
    "        if \"Embarked\" in self.dataframe.columns:\n",
    "            self.dataframe[\"Embarked\"].fillna(\n",
    "                self.dataframe[\"Embarked\"].mode()[0], inplace=True\n",
    "            )\n",
    "\n",
    "        # 4. 요금 처리 (중앙값으로 처리)\n",
    "        if \"Fare\" in self.dataframe.columns:\n",
    "            self.dataframe[\"Fare\"].fillna(self.dataframe[\"Fare\"].median(), inplace=True)\n",
    "\n",
    "        # 5. 새로운 특성 생성\n",
    "        # 가족의 관계(부모님, 사촌 등의 관계 없는 애는 다 isAlone으로 만듦 => 이거 중요함.)\n",
    "        if \"SibSp\" in self.dataframe.columns and \"Parch\" in self.dataframe.columns:\n",
    "            self.dataframe[\"FamilySize\"] = (\n",
    "                self.dataframe[\"SibSp\"] + self.dataframe[\"Parch\"] + 1\n",
    "            )\n",
    "            self.dataframe[\"IsAlone\"] = (self.dataframe[\"FamilySize\"] == 1).astype(int)\n",
    "\n",
    "        # 나이 그룹\n",
    "        if \"Age\" in self.dataframe.columns:\n",
    "            self.dataframe[\"AgeGroup\"] = pd.cut(\n",
    "                self.dataframe[\"Age\"],\n",
    "                bins=[0, 12, 18, 35, 60, 100],\n",
    "                labels=[0, 1, 2, 3, 4],\n",
    "            ).astype(int)\n",
    "            \n",
    "        # 요금 그룹\n",
    "        if \"Fare\" in self.dataframe.columns:\n",
    "            self.dataframe[\"FareGroup\"] = pd.qcut(\n",
    "                self.dataframe[\"Fare\"], q=4, labels=[0, 1, 2, 3]\n",
    "            ).astype(int)\n",
    "\n",
    "        # 원-핫 인코딩\n",
    "        if \"Sex\" in self.dataframe.columns:\n",
    "            sex_dummies = pd.get_dummies(self.dataframe[\"Sex\"], drop_first=True)\n",
    "            self.dataframe = pd.concat([self.dataframe, sex_dummies], axis=1)\n",
    "            self.dataframe.drop([\"Sex\"], axis=1, inplace=True)\n",
    "\n",
    "        if \"Embarked\" in self.dataframe.columns:\n",
    "            embarked_dummies = pd.get_dummies(\n",
    "                self.dataframe[\"Embarked\"], drop_first=True\n",
    "            )\n",
    "            self.dataframe = pd.concat([self.dataframe, embarked_dummies], axis=1)\n",
    "            self.dataframe.drop([\"Embarked\"], axis=1, inplace=True)\n",
    "        \n",
    "        # 나머지 결측 (평균)\n",
    "        self.dataframe.fillna(self.dataframe.mean(), inplace=True)\n",
    "        print(f\"전처리 후 특성 수: {len(self.dataframe.columns)}\")\n",
    "        print(f\"특성 목록: {list(self.dataframe.columns)}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        features = self.features[idx]\n",
    "        \n",
    "        #변환 적용\n",
    "        if self.transform:\n",
    "            features = self.transform(features)\n",
    "        \n",
    "        features = torch.FloatTensor(features)\n",
    "        \n",
    "        if self.is_train and self.targets is not None:\n",
    "            target = torch.LongTensor([self.targets[idx]])[0]\n",
    "            return features, target\n",
    "        else:\n",
    "            return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "773b74ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "class StandardScaleTransform:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, data):\n",
    "        self.scaler.fit(data)\n",
    "        self.fitted = True\n",
    "        return self\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\n",
    "                \"스케일러가 아직 학습되지 않았습니다. fit() 메서드를 먼저 호출하세요.\"\n",
    "            )\n",
    "\n",
    "        if sample.ndim == 1:\n",
    "            sample = sample.reshape(1, -1)\n",
    "            return self.scaler.transform(sample).flatten()\n",
    "        else:\n",
    "            return self.scaler.transform(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "880e8e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후 특성 수: 13\n",
      "특성 목록: ['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'IsAlone', 'AgeGroup', 'FareGroup', 'male', 'Q', 'S']\n",
      "전처리 후 특성 수: 12\n",
      "특성 목록: ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'IsAlone', 'AgeGroup', 'FareGroup', 'male', 'Q', 'S']\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "train_data = TitanicDataset(df_train, target_column=\"Survived\")\n",
    "test_data = TitanicDataset(df_test, is_train=False) # test_set에는 Survived 열이 없음 \n",
    "\n",
    "transform = StandardScaleTransform()\n",
    "transform.fit(train_data.features)\n",
    "\n",
    "# 데이터를 숫자로 바꾸는 전처리\n",
    "train_data.transform = transform\n",
    "test_data.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2d390c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset =  random_split(train_data, [0.2, 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd7b3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "tran_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "61d7d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = train_data.features.shape[1]\n",
    "# 특성의 개수를 넣어야함. (사람 수가 아님)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78638dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=[256, 128, 64], dropout_rate= 0.3): # 생성자의 매개변수가 가장 중요함. \n",
    "        super(TitanicNet, self).__init__()\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        for i, hidden_size in enumerate(hidden_size):\n",
    "            layers.extend([\n",
    "                nn.Linear(input_size, 256), # 12개 집어 넣어서 256 나옴 => 이 숫자는 내가 정하는 것인데, cnn, lmst 같은 것들을 보면서 숫자는 익히는 것임.\n",
    "                nn.BatchNorm1d(256), # 배치 정규화: 레이어로 들어가는 입력값이 한쪽으로 쏠리거나 너무 퍼지거나 너무 좁아지지 않게 해주는 것.\n",
    "                nn.ReLU(), # 활성화 함수 렐루\n",
    "                nn.Dropout(dropout_rate) # 50%의 확률로 아무거나 자름 # 학습 성능이 올라감 => 내려갈 수도 있음\n",
    "            ])\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        #출력층\n",
    "        layers.append(nn.Linear(prev_size, 2))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x) # 네트워크라고 하는 순방향 모델 완성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dad8980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = train_data.features.shape[1]\n",
    "model = TitanicNet(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209d7b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TitanicNet(\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Linear(in_features=12, out_features=256, bias=True)\n",
       "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.3, inplace=False)\n",
       "    (8): Linear(in_features=12, out_features=256, bias=True)\n",
       "    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.3, inplace=False)\n",
       "    (12): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model # 입력측 + 은닉층까지가 1개층 / 총 은닉 3계층 만든 것임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2cc0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
